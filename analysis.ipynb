{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1dcbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import lru_cache\n",
    "\n",
    "import chromadb\n",
    "import ir_datasets\n",
    "from ir_measures import ScoredDoc, calc_aggregate, nDCG\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils import persistent_cache\n",
    "\n",
    "dataset = ir_datasets.load(\"beir/nfcorpus\")\n",
    "model = SentenceTransformer(\"Qwen/Qwen3-Embedding-0.6B\")\n",
    "chroma_client = chromadb.Client()\n",
    "\n",
    "# chroma_client.delete_collection(name=\"beir_nfcorpus_documents\")\n",
    "# chroma_client.delete_collection(name=\"beir_nfcorpus_queries\")\n",
    "\n",
    "\n",
    "EMBEDDINGS_CACHE = \"./.cache/embeddings/\"\n",
    "EMBED_DIM = 1024\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ae35c7",
   "metadata": {},
   "source": [
    "Generate and cache the full embeddings first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b77862d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@persistent_cache.persistent_cache(\n",
    "    directory=EMBEDDINGS_CACHE, hash_filenames=True, file_type=\"json\"\n",
    ")\n",
    "def calculate_embeddings(text):\n",
    "    embeddings = model.encode(text)\n",
    "    embeddings = embeddings.tolist()\n",
    "    return {\"embeddings\": embeddings}\n",
    "\n",
    "\n",
    "@lru_cache(maxsize=7000)\n",
    "def fetch_embeddings(text):\n",
    "    embeddings = calculate_embeddings(text)\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "def create_collection(chroma_client):\n",
    "    chroma_collection_documents = chroma_client.get_or_create_collection(\n",
    "        name=\"beir_nfcorpus_documents\", metadata={\"hnsw:space\": \"cosine\"}\n",
    "    )\n",
    "    return chroma_collection_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf39ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_docs(retain_dim):\n",
    "    for doc in dataset.docs_iter():\n",
    "        doc_text = doc.title + \" \" + doc.text\n",
    "        doc_emb = fetch_embeddings(doc_text)[\"embeddings\"][:retain_dim]\n",
    "        chroma_collection_documents.add(\n",
    "            documents=[doc_text],\n",
    "            embeddings=[doc_emb],\n",
    "            metadatas=[{\"url\": doc.url, \"id\": doc.doc_id}],\n",
    "            ids=[doc.doc_id],\n",
    "        )\n",
    "\n",
    "\n",
    "def cache_all_queries(retain_dim):\n",
    "    SEARCH_PROMPT_PREFIX = \"Instruct: Given a web search query, retrieve relevant passages that answer the query\\nQuery:\"\n",
    "\n",
    "    for query in dataset.queries_iter():\n",
    "        query_text = SEARCH_PROMPT_PREFIX + \" \" + query.text\n",
    "        query_embed = calculate_embeddings(query_text)[\"embeddings\"][:retain_dim]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960d2573",
   "metadata": {},
   "source": [
    "Now that all the documents and queries has been embedded. Lets create a baseline that we can test over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c012036e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_query_embeddings(query):\n",
    "    query_embeddings = calculate_embeddings(query)[\"embeddings\"]\n",
    "    return query_embeddings\n",
    "\n",
    "\n",
    "def search(query_id, query_embeddings):\n",
    "    search_resp = chroma_collection_documents.query(query_embeddings=[query_embeddings])\n",
    "    # return search_resp[\"ids\"][0]\n",
    "    # return search_resp\n",
    "\n",
    "    result = []\n",
    "    for hit_index in range(len(search_resp[\"ids\"][0])):\n",
    "        # convert norm dist to similarity\n",
    "        similarity = 1 - search_resp[\"distances\"][0][hit_index]\n",
    "        result.append(ScoredDoc(query_id, search_resp[\"ids\"][0][hit_index], similarity))\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487032c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_collection(chroma_client):\n",
    "    try:\n",
    "        chroma_client.delete_collection(\"beir_nfcorpus_documents\")\n",
    "    except Exception as e:\n",
    "        print(\"collection doesnt exist\")\n",
    "\n",
    "\n",
    "delete_collection(chroma_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f018e1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = ir_datasets.load(\"beir/nfcorpus/test\")\n",
    "results = []\n",
    "\n",
    "for dim in tqdm(range(1, EMBED_DIM + 1), desc=\"Running with DIM\"):\n",
    "    run_results = []\n",
    "    metrics = [nDCG @ 10]\n",
    "\n",
    "    delete_collection(chroma_client)\n",
    "    chroma_collection_documents = create_collection(chroma_client)\n",
    "    index_docs(retain_dim=dim)\n",
    "\n",
    "    for query in test_dataset.queries_iter():\n",
    "        qid = query.query_id\n",
    "        query_text = query.text\n",
    "        query_embeddings = fetch_query_embeddings(query_text)[:dim]\n",
    "        run_results.extend(search(qid, query_embeddings))\n",
    "\n",
    "    metrics = calc_aggregate(metrics, test_dataset.qrels, run_results)\n",
    "    results.append({\"dimention\": dim, \"nDCG@10\": metrics[nDCG @ 10]})\n",
    "# print(\"Ranking metric NDCG@10 {:.4f}\".format(metrics[nDCG @ 10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63020f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(\"./analysis_results_all_dim.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbdb97b",
   "metadata": {},
   "source": [
    "Ranking metric NDCG@10 for rank profile: 0.3619"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "matrtoshka-analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
